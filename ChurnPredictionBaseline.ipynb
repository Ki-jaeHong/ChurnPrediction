{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3_QkgnAeElN_"
   },
   "source": [
    "Paper: https://www.andrew.cmu.edu/user/lakoglu/pubs/StackOverflow-churn.pdf\n",
    "\n",
    "Description of datasets: https://ia800107.us.archive.org/27/items/stackexchange/readme.txt\n",
    "\n",
    "Site for download of datasets: https://archive.org/details/stackexchange\n",
    "\n",
    "This code has 6 steps\n",
    "\n",
    "1. Load StackOverflow datasets as dataframe\n",
    "2. Extract and label the datasets for each task\n",
    "3. Extract features for each task\n",
    "4. Analyze features\n",
    "5. Train models for each task with the features\n",
    "6. Quantify the importance of each feature category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BIq6tvSgGX_u"
   },
   "source": [
    "1. Load StackOverflow datasets as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "SkhHqE16EqWg",
    "outputId": "b64410e7-64c7-4d87-8476-b4d8da62415a"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fsdakpOMEuhl"
   },
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WX1fzL0Ezx5"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2r9tJIIxE1vI"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "gdrive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIyjk-t9E3jo"
   },
   "outputs": [],
   "source": [
    "def store_df_at_google_drive(fname, df):\n",
    "    s = io.StringIO()\n",
    "    df.to_csv(s)\n",
    "    uploaded = gdrive.CreateFile({'title': fname, 'parents':[{'id': 'root'}]})\n",
    "    uploaded.SetContentString(s.getvalue())\n",
    "    uploaded.Upload()\n",
    "    print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
    "\n",
    "def load_df_at_google_drive(fname):\n",
    "    file_list = gdrive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList()\n",
    "    for file1 in file_list:\n",
    "        if (file1['title'] == fname):\n",
    "            downloaded = gdrive.CreateFile({'id': file1['id']})\n",
    "            s = io.StringIO(downloaded.GetContentString())\n",
    "            return pd.read_csv(s)\n",
    "    \n",
    "def load_dataset_from_google_drive(dir_id):\n",
    "    files = []\n",
    "    file_list = gdrive.ListFile({'q': \"'{}' in parents\".format(dir_id)}).GetList()\n",
    "    for f in file_list:\n",
    "    if f['title'] in ['Users.xml', 'Posts.xml','users_reduce.pkl', 'posts_reduce.pkl']:\n",
    "        print('  Load file: {}'.format(f['title']))\n",
    "        f_ = gdrive.CreateFile({'id': f['id']})\n",
    "        f_.GetContentFile(f['title'])\n",
    "        files.append(f['title'])\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_9rM193FeAn"
   },
   "outputs": [],
   "source": [
    "files = load_dataset_from_google_drive('1Fp_7GDH_t7xfnU8aXeKrcBC54_nECOcu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbh_OQyiGK2Z"
   },
   "outputs": [],
   "source": [
    "users_df = pd.read_pickle(\"{}.pkl\".format('users_reduce'))   # shape: (992,110, 3)\n",
    "posts_df = pd.read_pickle(\"{}.pkl\".format('posts_reduce'))   # shape: (11,324,326, 10)\n",
    "\n",
    "users_df.shape, posts_df.shape   # Total dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ugS0FTGWGhg9"
   },
   "source": [
    "2. Extract and label the datasets for each tasks\n",
    "\n",
    "You should extract the dataset for the period of the dataset: July 31, 2008 ~ July 31, 2012\n",
    "\n",
    "There are 2 tasks:\n",
    "\n",
    "A. After a user's K-th post, predict how likely it is that the user will churn\n",
    "\n",
    "B. After the T-th day from the account creation of a user, predict how likely it is that the user will churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ztCnzaoPGQTJ"
   },
   "outputs": [],
   "source": [
    "def getIthOfPosts(posts):\n",
    "    print('getIthOfPosts')\n",
    "    posts.sort_values(by=['OwnerUserId', 'CreationDate'], inplace=True)\n",
    "    posts.reset_index(level=0, inplace=True)\n",
    "    posts['id_owner_time'] = posts.index\n",
    "    first_posts = posts.groupby('OwnerUserId')['id_owner_time'].min().to_frame()\n",
    "    tmp = posts.join(first_posts, on='OwnerUserId', how='inner', lsuffix='F', rsuffix='P')\n",
    "    posts['ith'] = tmp['id_owner_timeF'] - tmp['id_owner_timeP'] + 1\n",
    "    posts = posts.drop(['id_owner_time'], axis=1)\n",
    "    return posts\n",
    "\n",
    "# You should extract the dataset for the period of the dataset: July 31, 2008 ~  July 31, 2012\n",
    "start_time = pd.to_datetime('2008-07-31')\n",
    "end_time = pd.to_datetime('2012-07-31')\n",
    "end_time_2 = pd.to_datetime('2012-01-31')\n",
    "\n",
    "posts_df = posts_df[(posts_df['CreationDate'] >= start_time) & (posts_df['CreationDate'] <= end_time)]\n",
    "users_df = users_df[(users_df['CreationDate'] >= start_time) & (users_df['CreationDate'] <= end_time_2)]\n",
    "\n",
    "\n",
    "posts_df = getIthOfPosts(posts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "azQSCsXHHAza"
   },
   "outputs": [],
   "source": [
    "# Dataset in Task 1\n",
    "#   Posts: Extract K posts of each user\n",
    "#   Users: Extract users who post at least K\n",
    "\n",
    "\n",
    "def getTask1Posts(posts, K):\n",
    "    tmp = posts[posts['ith'] == K]['OwnerUserId'].to_frame()\n",
    "    tmp = tmp.set_index('OwnerUserId')\n",
    "    tmp = posts[posts['OwnerUserId'].isin(tmp.index)]\n",
    "    return tmp[tmp['ith'] <= K]\n",
    "\n",
    "\n",
    "def getTask1Users(users, posts, K):\n",
    "    users['num_posts'] = posts.groupby('OwnerUserId')['OwnerUserId'].count()\n",
    "    users = users[users['num_posts'] >= K]\n",
    "    return users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlsZBbM8ctQv"
   },
   "outputs": [],
   "source": [
    "list_of_K = range(1, 21)\n",
    "users_of_task1, posts_of_task1 = {}, {}\n",
    "\n",
    "\n",
    "for K in list_of_K:\n",
    "    posts_of_task1[K] = getTask1Posts(posts_df, K)\n",
    "    users_of_task1[K] = getTask1Users(users_df, posts_df, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OpHDgehj4gde"
   },
   "outputs": [],
   "source": [
    "# Churn in Task 1\n",
    "#   Churners: Users who did not post for at least 6 months from their K-th post \n",
    "#   Stayers:  Users who created at least one post within the 6 months from their K-th post\n",
    "\n",
    "def prepareFeaturesTask1(users, posts, K):\n",
    "    tmp = posts[posts['ith']==K]['OwnerUserId'].to_frame()\n",
    "    tmp = tmp.set_index('OwnerUserId')\n",
    "    posts = posts[posts['OwnerUserId'].isin(tmp.index)]\n",
    "\n",
    "    posts_task = posts[posts['OwnerUserId'].isin(users.index)]\n",
    "    posts_Kth_time = posts_task[posts_task['ith']==K]\n",
    "    posts_Kth_time = posts_Kth_time.set_index('OwnerUserId')['CreationDate']\n",
    "    posts_deadline = posts_Kth_time + pd.tseries.offsets.DateOffset(months=6)\n",
    "    \n",
    "    posts_stayer = posts_task[posts_task['ith'] > K].groupby('OwnerUserId')['CreationDate'].min().to_frame()\n",
    "    posts_stayer = posts_stayer.merge(posts_deadline, on='OwnerUserId', how='left', suffixes=('_left', '_right'))\n",
    "    \n",
    "    posts_churner1 = posts_stayer[posts_stayer['CreationDate_left'] > posts_stayer['CreationDate_right']]\n",
    "    posts_churner1['is_churn'] = 1\n",
    "    posts_churner1 = posts_churner1[['is_churn']]\n",
    "    posts_stayer = posts_stayer[posts_stayer['CreationDate_left'] <= posts_stayer['CreationDate_right']]\n",
    "    posts_stayer['is_churn'] = 0    \n",
    "    posts_stayer = posts_stayer[['is_churn']]\n",
    "       \n",
    "    posts_churner2 = posts_task[posts_task['ith'] >= K].groupby('OwnerUserId').count()\n",
    "    posts_churner2 = posts_churner2[posts_churner2['CreationDate'] == 1][['CreationDate']]\n",
    "    posts_churner2['is_churn'] = 1\n",
    "    posts_churner2 = posts_churner2[['is_churn']]\n",
    "    \n",
    "    posts = pd.concat([posts_stayer, posts_churner1, posts_churner2])\n",
    "    posts = posts.rename(columns={'OwnerUserId': 'Id'})\n",
    "    users['is_churn'] = 0\n",
    "    users.update(posts)\n",
    "    return users\n",
    "\n",
    "features_of_task1 = {}\n",
    "\n",
    "for K in list_of_K:\n",
    "    features_of_task1[K] = prepareFeaturesTask1(users_of_task1[K], posts_df, K)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ln3Q7trGg06"
   },
   "outputs": [],
   "source": [
    "# Dataset in Task 2\n",
    "#   Users: Extract users who post at least 1\n",
    "#   Posts: Extract posts which create before T day from the account creation of the owner\n",
    "\n",
    "def getCreationDateOfOwner(users, posts):\n",
    "    posts['DataframeIndex'] = posts.index\n",
    "    posts['CreationDateOfOwner'] = posts.set_index('OwnerUserId')\\\n",
    "            .join(users, how='inner', rsuffix='OfOwner')\\\n",
    "            .set_index('DataframeIndex')['CreationDateOfOwner']\n",
    "    posts = posts.drop(['DataframeIndex'], axis=1)\n",
    "    return posts['CreationDateOfOwner']\n",
    "\n",
    "  \n",
    "def getTask2Posts(users, posts, T):\n",
    "    if 'CreationDateOfUser' not in posts.columns:\n",
    "        posts['CreationDateOfOwner'] = getCreationDateOfOwner(users, posts)\n",
    "    observation_deadline = posts['CreationDateOfOwner'] + pd.offsets.Day(T)\n",
    "    posts = posts[posts['CreationDate'] <= observation_deadline]\n",
    "    return posts\n",
    "  \n",
    "def getTask2Users(users, posts):\n",
    "    users['num_posts'] = posts.groupby('OwnerUserId')['OwnerUserId'].count()\n",
    "    users = users[users['num_posts'] >= 1]\n",
    "    return users\n",
    "  \n",
    "list_of_T = [7, 15, 30]\n",
    "users_of_task2 = {}\n",
    "posts_of_task2 = {}\n",
    "\n",
    "for T in list_of_T:\n",
    "    posts_of_task2[T] = getTask2Posts(users_df, posts_df, T)\n",
    "    users_of_task2[T] = getTask2Users(users_df, posts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYIvRp-nY8q-"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4KFrYJP0H8H8"
   },
   "outputs": [],
   "source": [
    "# Churn in Task2\n",
    "#   Churners: Users who did not post for at least 6 months from T days after account creation\n",
    "#   Stayers:  Users who created at least one post within the 6 months from T days after account creation\n",
    "\n",
    "def prepareFeaturesTask2(users, posts, T=30):\n",
    "    if 'CreationDateOfUser' not in posts.columns:\n",
    "        posts['CreationDateOfOwner'] = getCreationDateOfOwner(users, posts)\n",
    "    users = getTask1Users(users, posts, K=1)\n",
    "    observe_deadline = posts['CreationDateOfOwner'] + pd.offsets.Day(T)\n",
    "    churn_deadline = observe_deadline + pd.tseries.offsets.DateOffset(months=6)\n",
    "    posts_observed = posts[(posts['CreationDate'] <= observe_deadline) & (posts['CreationDate'] >= posts['CreationDateOfOwner'])]\n",
    "    posts_after_observe = posts[(posts['CreationDate'] <= churn_deadline) & (posts['CreationDate'] > observe_deadline)]\n",
    "    label_df = users.reindex((posts_observed.groupby('OwnerUserId')['OwnerUserId'].count() > 0).index)\n",
    "    stayers = (posts_after_observe.groupby('OwnerUserId')['OwnerUserId'].count() > 0).index\n",
    "    churners = list(set(label_df.index) - set(stayers))\n",
    "    label_df['is_churn'] = 0.\n",
    "    label_df.loc[churners, 'is_churn'] = 1.\n",
    "    return label_df\n",
    "\n",
    "features_of_task2 = {}\n",
    "for T in list_of_T:\n",
    "    features_of_task2[T] = prepareFeaturesTask2(users_of_task2[T], posts_df, T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tTUabuRXIMeh"
   },
   "source": [
    "3. Extract features for each task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qeu0qyZjIVaW"
   },
   "source": [
    "3-1. Temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1BwDqBD4H_my"
   },
   "outputs": [],
   "source": [
    "# Temporal features 1: gap1\n",
    "def getTimeGap1OfUser(users, posts):\n",
    "    creation_date_user = users['CreationDate']\n",
    "    creation_date_first_post = posts.groupby('OwnerUserId')['CreationDate'].min()\n",
    "    return (creation_date_first_post - creation_date_user).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blqxv9rsIiFT"
   },
   "outputs": [],
   "source": [
    "# Temporal features 2: gapK\n",
    "\n",
    "def getTimeGapkOfPosts(posts, k):\n",
    "    date_1 = posts[posts['ith'] == (k-1)].sort_values('OwnerUserId')\n",
    "    date_2 = posts[posts['ith'] == k].sort_values('OwnerUserId')\n",
    "    date_2 = date_2.set_index('OwnerUserId')\n",
    "    date_1 = date_1.set_index('OwnerUserId')\n",
    "    result = (date_2['CreationDate'] - date_1['CreationDate']).dt.total_seconds() / 60  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpApw_8FMA8O"
   },
   "outputs": [],
   "source": [
    "# Temporal features 3: last_gap\n",
    "def getTimeLastGapOfPosts(posts):\n",
    "    last_posts = posts.groupby('OwnerUserId')['CreationDate'].max().to_frame()\n",
    "    tmp = posts.join(last_posts, on='OwnerUserId', how='inner', lsuffix='F', rsuffix='P')\n",
    "    tmp = tmp[tmp['CreationDateF'] < tmp['CreationDateP']].groupby('OwnerUserId')['CreationDateF'].max().to_frame()\n",
    "    return (last_posts['CreationDate'] - tmp['CreationDateF']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpmdwUxkMFdq"
   },
   "outputs": [],
   "source": [
    "# Temporal features 4: time_since_last_post\n",
    "def getTimeSinceLastPost(users, posts, T):\n",
    "    last_post_date = posts.groupby('OwnerUserId')['CreationDate'].max()\n",
    "    creation_after_T_days_date = users['CreationDate'] + pd.offsets.Day(T)\n",
    "    return (creation_after_T_days_date - last_post_date).dt.total_seconds() / 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PhBuCzYXMQ4A"
   },
   "outputs": [],
   "source": [
    "# Temporal features 5: mean_gap\n",
    "def getTimeMeanGap(posts):\n",
    "    last_post_date = posts.groupby('OwnerUserId')['CreationDate'].max()\n",
    "    first_post_date = posts.groupby('OwnerUserId')['CreationDate'].min()\n",
    "    num_posts = posts.groupby('OwnerUserId')['CreationDate'].count()\n",
    "    return (last_post_date - first_post_date).dt.total_seconds() / 60 / num_posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUa-4pyI96fP"
   },
   "outputs": [],
   "source": [
    "# Extract temporal features for task1\n",
    "for K in list_of_K:\n",
    "    features_of_task1[K]['gap1'] = getTimeGap1OfUser(users_of_task1[K], posts_of_task1[K])\n",
    "    for k in range(2, K+1):\n",
    "        features_of_task1[K]['gap{}'.format(k)] = getTimeGapkOfPosts(posts_of_task1[K], k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgicxCHzBHs2"
   },
   "outputs": [],
   "source": [
    "# Figure 2: Gap between posts\n",
    "#    For a user who churns, gap between consecutive posts keeps increasing. \n",
    "#    Gaps for those who stay are much lower, and stabilize around 20,000 minutes,\n",
    "#    indicating routine posting activity in every ≈2 weeks.\n",
    "clist = []\n",
    "slist = []\n",
    "for K in list_of_K:\n",
    "    subgroup = features_of_task1[K]\n",
    "    churners_gap = []\n",
    "    stayers_gap = []\n",
    "    for i in range(2, K+1):\n",
    "        gapK = 'gap{}'.format(i)\n",
    "        sum_gapK = list(subgroup.groupby('is_churn')[gapK].sum())\n",
    "        count_gapK = list(subgroup.groupby('is_churn')[gapK].count())\n",
    "        if len(sum_gapK) < 2:\n",
    "            break\n",
    "        churners_gap.append(sum_gapK[1] / count_gapK[1])\n",
    "        stayers_gap.append(sum_gapK[0] / count_gapK[0])\n",
    "\n",
    "    clist.append(churners_gap)\n",
    "    slist.append(stayers_gap)\n",
    "    \n",
    "    print(\"K={}\".format(K))\n",
    "    plt.plot(churners_gap, '-o', label='churner')\n",
    "    plt.plot(stayers_gap, '-o', label='stayer')\n",
    "    plt.legend()\n",
    "    plt.axis((0,20,0,15e4))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "DQFQBkpbB6_D",
    "outputId": "d6252c0f-7420-4c45-8720-b02fd77fdf0c"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "axlist = [ax1, ax2, ax3, ax4]\n",
    "for c, s, ax in zip(clist[1:], slist[1:], axlist):\n",
    "    ax.plot(c, '-o', label='churner')\n",
    "    ax.plot(s, '-o', label='stayer')\n",
    "    ax.legend()\n",
    "    ax.axis((0,20,0,15e4))\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "axlist = [ax1, ax2, ax3, ax4]\n",
    "for c, s, ax in zip(clist[-4:], slist[-4:], axlist):\n",
    "    ax.plot(c, '-o', label='churner')\n",
    "    ax.plot(s, '-o', label='stayer')\n",
    "    ax.legend()\n",
    "    ax.axis((0,20,0,15e4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JlWoElW9CFcV"
   },
   "outputs": [],
   "source": [
    "# Extract temporal features for task2\n",
    "for T in list_of_T:\n",
    "    users, posts = users_of_task2[T], posts_of_task2[T]\n",
    "    features_of_task2[T]['gap1'] = getTimeGap1OfUser(users, posts)\n",
    "    features_of_task2[T]['last_gap'] = getTimeLastGapOfPosts(posts).fillna(features_of_task2[T]['gap1'])\n",
    "    #features_of_task2[T]['last_gap'] = getTimeLastGapOfPosts(posts).fillna(0)\n",
    "    features_of_task2[T]['time_since_last_post'] = getTimeSinceLastPost(users, posts, T)\n",
    "    features_of_task2[T]['mean_gap'] = getTimeMeanGap(posts)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rB7E22Q4MSWR"
   },
   "source": [
    "3-2. Frequency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wpECyr9kMTvJ"
   },
   "outputs": [],
   "source": [
    "# Frequency features 1: num_answers\n",
    "# Frequency features 2: num_questions\n",
    "def getNumAnswers(posts):\n",
    "    answers = posts[posts['PostTypeId'] == 2]\n",
    "    return answers.groupby('OwnerUserId')['OwnerUserId'].count()\n",
    "\n",
    "def getNumQuestions(posts):\n",
    "    questions = posts[posts['PostTypeId'] == 1]\n",
    "    return questions.groupby('OwnerUserId')['OwnerUserId'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KqmIPayXNHqY"
   },
   "outputs": [],
   "source": [
    "# Frequency features 3: ans_ques_ratio\n",
    "def getAnsQuesRatio(num_answers, num_questions):\n",
    "    # Use Laplace Smoothing\n",
    "    return (num_answers + 1) / (num_questions + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNWqcYeONJvE"
   },
   "outputs": [],
   "source": [
    "# Frequency features 4: num_posts\n",
    "def getNumPosts(posts):\n",
    "    return posts.groupby('OwnerUserId')['OwnerUserId'].count().astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "_jRcG-juDigR",
    "outputId": "02dd676e-7d04-494b-ac67-c6d638a82d59"
   },
   "outputs": [],
   "source": [
    "# Extract frequency features of task1\n",
    "for K in list_of_K:\n",
    "    users, posts = users_of_task1[K], posts_of_task1[K]\n",
    "    features_of_task1[K]['num_answers'] = getNumAnswers(posts)\n",
    "    features_of_task1[K]['num_questions'] = getNumQuestions(posts)\n",
    "    features_of_task1[K] = features_of_task1[K].fillna({'num_answers':0, 'num_questions':0})\n",
    "    features_of_task1[K]['ans_que_ratio'] = \\\n",
    "        getAnsQuesRatio(features_of_task1[K]['num_answers'], features_of_task1[K]['num_questions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHo_ds2wFRWB"
   },
   "outputs": [],
   "source": [
    "# Extract frequency features of task2\n",
    "for T in list_of_T:\n",
    "    users, posts = users_of_task2[T], posts_of_task2[T]\n",
    "    features_of_task2[T]['num_answers'] = getNumAnswers(posts)\n",
    "    features_of_task2[T]['num_questions'] = getNumQuestions(posts)\n",
    "    features_of_task2[T] = features_of_task2[T].fillna({'num_answers':0,'num_questions':0})\n",
    "    features_of_task2[T]['ans_que_ratio'] = \\\n",
    "        getAnsQuesRatio(features_of_task2[T]['num_answers'], features_of_task2[T]['num_questions'])\n",
    "    features_of_task2[T]['num_posts'] = getNumPosts(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826
    },
    "colab_type": "code",
    "id": "ItDHgLi6FtEA",
    "outputId": "2f0343a2-46ef-4e90-fd64-ffb03776290a"
   },
   "outputs": [],
   "source": [
    "# Figure 3: # Answers vs Churn probability\n",
    "#    The probability of churning for a user decreases the more answers s/he provides.\n",
    "#    It is even lower if s/he asks more questions alongside.\n",
    "\n",
    "min_num_users = 50\n",
    "for T in list_of_T:\n",
    "    task2 = features_of_task2[T]\n",
    "    for num_que_ask in range(5):\n",
    "        subgroup = task2[task2['num_questions'] == num_que_ask]\n",
    "        churn_probs = []\n",
    "        num_answers = list(set(subgroup['num_answers']))\n",
    "        num_answers.sort()\n",
    "        for num_ans in num_answers:\n",
    "            subsubgroup = subgroup[subgroup['num_answers'] == num_ans]\n",
    "            prob = sum(subsubgroup['is_churn']) / subsubgroup.shape[0]\n",
    "            if subsubgroup.shape[0] >= min_num_users:\n",
    "                churn_probs.append((num_ans, prob))\n",
    "\n",
    "        plt.plot([np.log10(x[0]+1) for x in churn_probs],\n",
    "                 [np.log10(x[1]+0.01) for x in churn_probs],\n",
    "                 '-o',\n",
    "                 label='{} ques asked'.format(num_que_ask))\n",
    "    print(\"# Answers vs Churn probability\")\n",
    "    plt.legend()\n",
    "    plt.axis((0,2,-2,0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYDXzIXLNN58"
   },
   "source": [
    "3-3. Knowledge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W1GRvX0PRk_"
   },
   "outputs": [],
   "source": [
    "# For the fast extraction, prepare questions x answers\n",
    "def preprocessForKnowledgeFeaturesForTask1(users, posts, all_posts):\n",
    "    answers = posts[posts['PostTypeId'] == 2]\n",
    "    questions = posts[posts['PostTypeId'] == 1]\n",
    "    all_answers = all_posts[all_posts['PostTypeId'] == 2]\n",
    "    all_questions = all_posts[all_posts['PostTypeId'] == 1]\n",
    "\n",
    "    qnta = all_answers.set_index('ParentId')\\\n",
    "        .join(questions, how='inner',\\\n",
    "              lsuffix='A', rsuffix='Q')\n",
    "    tqna = answers.set_index('ParentId')\\\n",
    "        .join(all_questions, how='inner',\\\n",
    "              lsuffix='A', rsuffix='Q')\n",
    "    return answers, questions, qnta, tqna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-D6rXdOa4ms"
   },
   "outputs": [],
   "source": [
    "# For the fast extraction, prepare questions x answers\n",
    "def preprocessForKnowledgeFeaturesForTask2(users, posts):\n",
    "    answers = posts[posts['PostTypeId'] == 2]\n",
    "    questions = posts[posts['PostTypeId'] == 1]\n",
    "    qna = answers\\\n",
    "        .set_index('ParentId').join(questions, how='inner',\\\n",
    "                                    lsuffix='A', rsuffix='Q')\n",
    "    return answers, questions, qna, qna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7c9nOpPNLdO"
   },
   "outputs": [],
   "source": [
    "# Knowledge features 1: accepted_answerer_rep\n",
    "def getRepOfAcceptedAnswerer(users, answers, questions, qnta, tqna):\n",
    "    reputations = users.loc[:, ['Reputation']]\n",
    "    rep_accepted_ans = qnta[qnta['AcceptedAnswerIdQ'] == qnta['IdA']]\\\n",
    "        .set_index('OwnerUserIdA')\\\n",
    "        .join(reputations, how='inner')\\\n",
    "        .groupby('OwnerUserIdQ')['Reputation'].mean()\n",
    "    return rep_accepted_ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVLRFX12NPCZ"
   },
   "outputs": [],
   "source": [
    "# Knowledge features 2: max_rep_answerer \n",
    "def getMaxRepAmongAnswerer(users, answers, questions, qnta, tqna):\n",
    "    reputations = users.loc[:, ['Reputation']]\n",
    "    rep_max_ans = qnta.set_index('OwnerUserIdA')\\\n",
    "        .join(reputations, how='inner')\\\n",
    "        .groupby('OwnerUserIdQ')['Reputation'].max()\n",
    "    return rep_max_ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h7F5YoZ7NQUk"
   },
   "outputs": [],
   "source": [
    "# Knowledge features 3: num_que_answered\n",
    "def getNumQueAnswered(users, answers, questions, qnta, tqna):\n",
    "    # number of questions posted by the user that got answered\n",
    "    #questions = posts[posts['PostTypeId'] == 1]\n",
    "    answered_questions = questions[questions['AnswerCount'] > 0]\n",
    "    return answered_questions.groupby('OwnerUserId')['AnswerCount'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3vZxSTm5NRPx"
   },
   "outputs": [],
   "source": [
    "# Knowledge features 4: time_for_first_ans\n",
    "def getTimeForFirstAns(users, answers, questions, qnta, tqna):\n",
    "    tmp =  qnta[qnta['CreationDateQ'] < qnta['CreationDateA']]\n",
    "    tmp['time_for_ans'] = (tmp['CreationDateA'] - tmp['CreationDateQ']).dt.total_seconds() / 60\n",
    "    questions['time_for_first_ans'] = tmp.groupby(by=tmp.index)['time_for_ans'].min()\n",
    "    return questions.groupby('OwnerUserId')['time_for_first_ans'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-tFQfJQNSe0"
   },
   "outputs": [],
   "source": [
    "# Knowledge features 5: rep_questioner\n",
    "def getAvgRepOfQuestioner(users, answers, questions, qnta, tqna):\n",
    "    # Avg. reputation of the user whose question was answered\n",
    "    reputations = users.loc[:, ['Reputation']]\n",
    "    rep_accepted_ans = tqna.set_index('OwnerUserIdQ')\\\n",
    "        .join(reputations, how='inner')\\\n",
    "        .groupby('OwnerUserIdA')['Reputation'].mean()\n",
    "    return rep_accepted_ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3DfugZxXNTeC"
   },
   "outputs": [],
   "source": [
    "# Knowledge features 6: rep_answerers\n",
    "def getAvgRepOfAnswerer(users, answers, questions, qnta, tqna):\n",
    "    # Avg. reputation of the users who answered the question\n",
    "    reputations = users.loc[:, ['Reputation']]\n",
    "    rep_accepted_ans = qnta.set_index('OwnerUserIdA')\\\n",
    "        .join(reputations, how='inner')\\\n",
    "        .groupby('OwnerUserIdQ')['Reputation'].mean()\n",
    "    return rep_accepted_ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9sD-x4HhNUyX"
   },
   "outputs": [],
   "source": [
    "# Knowledge features 7: rep_co_answerers\n",
    "def getAvgRepOfCoAnswerer(users, answers, questions, qnta, tqna):\n",
    "    reputations = users.loc[:, ['Reputation']]    \n",
    "    rep_ans = answers.set_index('OwnerUserId')\\\n",
    "        .join(reputations, how='inner')\\\n",
    "        .set_index('ParentId')\\\n",
    "        .join(questions, how='inner', lsuffix='A', rsuffix='Q')\n",
    "    avg_rep_ans = rep_ans.groupby(by=rep_ans.index)['Reputation'].mean()\n",
    "    rep_co_answerer = answers.set_index('ParentId')\\\n",
    "        .join(avg_rep_ans, how='inner')\\\n",
    "        .set_index('OwnerUserId')\n",
    "    return rep_co_answerer.groupby(by=rep_co_answerer.index)['Reputation'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YBNqrO0jNWHJ"
   },
   "outputs": [],
   "source": [
    "# Knowledge features 8: num_answers_recvd\n",
    "def getAvgNumAnsReceived(users, answers, questions, qnta, tqna):\n",
    "    #questions = posts[posts['PostTypeId'] == 1]\n",
    "    return questions.fillna({'AnswerCount': 0}).groupby('OwnerUserId')['AnswerCount'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BlYoLY17HvpP",
    "outputId": "a0deb7c6-1233-4593-b828-db2d40832fb0"
   },
   "outputs": [],
   "source": [
    "# Extract knowledge features of task 1\n",
    "for K in list_of_K:\n",
    "    print(\"Extract knowledge features of task1(K=\",K,\")\")\n",
    "    users, posts = users_of_task1[K], posts_of_task1[K]\n",
    "    answers, questions, qnta, tqna = preprocessForKnowledgeFeaturesForTask1(users, posts, posts_df)\n",
    "    features_of_task1[K]['accepted_answerer_rep'] = getRepOfAcceptedAnswerer(users, answers, questions,  qnta, tqna)\n",
    "    features_of_task1[K]['max_rep_answerer'] = getMaxRepAmongAnswerer(users, answers, questions,  qnta, tqna)\n",
    "    features_of_task1[K]['num_que_answered'] = getNumQueAnswered(users, answers, questions,  qnta, tqna)\n",
    "    features_of_task1[K]['time_for_first_ans'] = getTimeForFirstAns(users, answers, questions, qnta, tqna)\n",
    "    features_of_task1[K]['rep_questioner'] = getAvgRepOfQuestioner(users, answers, questions, qnta, tqna)\n",
    "    features_of_task1[K]['rep_answerers'] = getAvgRepOfAnswerer(users, answers, questions, qnta, tqna)\n",
    "    features_of_task1[K]['rep_co_answerers'] = getAvgRepOfCoAnswerer(users, answers, questions, qnta, tqna)\n",
    "    features_of_task1[K]['num_answers_recvd'] = getAvgNumAnsReceived(users, answers, questions, qnta, tqna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "colab_type": "code",
    "id": "qSsmpTI_L3Gr",
    "outputId": "3b92222d-e010-4bcd-b3a7-9649ae86dda6"
   },
   "outputs": [],
   "source": [
    "for T in list_of_T:\n",
    "    print(\"Extract knowledge features of task2(T=)\",T,\")\")\n",
    "    users, posts = users_of_task2[T], posts_of_task2[T]\n",
    "    answers, questions, qna, qna1 = preprocessForKnowledgeFeaturesForTask2(users, posts)\n",
    "    features_of_task2[T]['accepted_answerer_rep'] = getRepOfAcceptedAnswerer(users, answers, questions, qna, qna1)\n",
    "    features_of_task2[T]['max_rep_answerer'] = getMaxRepAmongAnswerer(users, answers, questions, qna, qna1)\n",
    "    features_of_task2[T]['num_que_answered'] = getNumQueAnswered(users, answers, questions, qna, qna1)\n",
    "    features_of_task2[T]['time_for_first_ans'] = getTimeForFirstAns(users, answers, questions, qna, qna1)\n",
    "    features_of_task2[T]['rep_questioner'] = getAvgRepOfQuestioner(users, answers, questions, qna, qna1)\n",
    "    features_of_task2[T]['rep_answerers'] = getAvgRepOfAnswerer(users, answers, questions, qna, qna1)\n",
    "    features_of_task2[T]['rep_co_answerers'] = getAvgRepOfCoAnswerer(users, answers, questions, qna, qna1)\n",
    "    features_of_task2[T]['num_answers_recvd'] = getAvgNumAnsReceived(users, answers, questions, qna, qna1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "9MT48B2mVZkQ",
    "outputId": "8936d901-91dc-4198-fdb9-52672886e5b3"
   },
   "outputs": [],
   "source": [
    "# Figure 4: K vs Time taken for the first answer to arrive\n",
    "#  The more the time taken for a user to receive an answer, \n",
    "#  the lesser the satisfaction level and the more the chances of churning.\n",
    "churners_time = []\n",
    "stayers_time = []\n",
    "for K in list_of_K:\n",
    "    subgroup = features_of_task1[K]\n",
    "    churners = subgroup[subgroup['is_churn'] == 1][subgroup['time_for_first_ans'] > 0] \n",
    "    stayers = subgroup[subgroup['is_churn'] == 0][subgroup['time_for_first_ans'] > 0]\n",
    "    churners_time.append(churners['time_for_first_ans'].mean())\n",
    "    stayers_time.append(stayers['time_for_first_ans'].mean())\n",
    "    \n",
    "\n",
    "plt.plot(churners_time, '-o', label='churner')\n",
    "plt.plot(stayers_time, '-o', label='stayer')\n",
    "plt.legend()\n",
    "# plt.axis((0,20,8e3,22e3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6xXsmwjf8I2"
   },
   "source": [
    "Implement the other features yourself!!\n",
    "\n",
    "3-4. Speed features\n",
    "\n",
    "3-5. Quality features\n",
    "\n",
    "3-6. Consistency features\n",
    "\n",
    "3-7. Gratitude features\n",
    "\n",
    "3-8. Competitiveness features\n",
    "\n",
    "3-9. Content features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_dudtEkMMr7O"
   },
   "outputs": [],
   "source": [
    "# Store the whole features of task1 to Google Drive\n",
    "for K in list_of_K:\n",
    "    store_df_at_google_drive('task1_{}posts_features.csv'.format(K), features_of_task1[K])\n",
    "    #features_of_task1[K].to_pickle('task1_{}posts_important_features.pkl'.format(K))\n",
    "    #features_of_task1[K].to_csv('task1_{}posts_important_features.csv'.format(K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kh4gc3g0NDI-"
   },
   "outputs": [],
   "source": [
    "for T in list_of_T:\n",
    "    store_df_at_google_drive('task2_{}posts_features.csv'.format(T), features_of_task2[T])\n",
    "    #features_of_task2[T].to_pickle('task2_{}days_important_features.pkl'.format(T))\n",
    "    #features_of_task2[T].to_csv('task2_{}days_important_features.csv'.format(T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fhh-YaDUas2l"
   },
   "source": [
    "5. Train models for each tasks with the features\n",
    "\n",
    "    1. Decision Tree\n",
    "    2. SVM (Linear)\n",
    "    3. SVM (RBF)\n",
    "    4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CR4RcZp8dZFe"
   },
   "outputs": [],
   "source": [
    "def fill_nan(features):\n",
    "    if 'time_for_first_ans' in features.columns and np.isnan(features['time_for_first_ans']).sum(0):\n",
    "        features['time_for_first_ans'] = 1 / features['time_for_first_ans']\n",
    "        features['time_for_first_ans'] = features['time_for_first_ans'].replace([np.nan], 0)\n",
    "    fill_constants = {\n",
    "        'accepted_answerer_rep': 0,\n",
    "        'max_rep_answerer': 0,\n",
    "        'num_que_answered': 0, \n",
    "        'rep_questioner': 0,\n",
    "        'rep_answerers': 0,\n",
    "        'rep_co_answerers': 0,\n",
    "        'num_answers_recvd': 0\n",
    "    }\n",
    "    return features.fillna(fill_constants)\n",
    "                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b0d6jNmw2ipN"
   },
   "outputs": [],
   "source": [
    "for K in list_of_K:\n",
    "    print(\"Fill NaN of task1(K=\",K,\")\")\n",
    "    features_of_task1[K] = fill_nan(features_of_task1[K])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObxxJXT32irv"
   },
   "outputs": [],
   "source": [
    "for T in list_of_T:\n",
    "    print(\"Fill NaN of task2(T=)\",T,\")\")\n",
    "    features_of_task2[T] = fill_nan(features_of_task2[T])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZM9rDE9WO7e"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "\n",
    "def LogisticRegression_(*arg, **kwarg):\n",
    "    kwarg['max_iter'] = 1e3\n",
    "    kwarg['solver'] = 'saga'\n",
    "    kwarg['n_jobs'] = 8\n",
    "    return LogisticRegression(*arg, **kwarg)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pmEBV3SA9fg6"
   },
   "outputs": [],
   "source": [
    "def learn_model(data, train_features, target='is_churn', model=DecisionTreeClassifier, seed=seed):\n",
    "    X = data[train_features]\n",
    "    y = data[target]\n",
    "    print(model.__name__)\n",
    "        \n",
    "    ### 10-fold cross validation ###\n",
    "    acc_list = []\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        ### Under-sampling ###\n",
    "        churners = y_train[y_train == 1].index\n",
    "        stayers = y_train[y_train == 0].index\n",
    "        n_churn = len(churners)\n",
    "        n_stay = len(stayers)\n",
    "        if n_churn > n_stay:\n",
    "            churners = np.random.choice(churners, n_stay, replace=False)\n",
    "        else:\n",
    "            stayers = np.random.choice(stayers, n_churn, replace=False)\n",
    "        train_index = np.array(list(churners) + list(stayers))\n",
    "        X_train, y_train = X.reindex(train_index), y.reindex(train_index)\n",
    "\n",
    "        ### Learn Model ###\n",
    "        mdl = model().fit(X_train, y_train)\n",
    "        pred = mdl.predict(X_test)\n",
    "        acc = (pred == y_test)\n",
    "        acc_list.append(sum(acc)*100/len(acc))\n",
    "    return acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QjrE1aqQWO9t",
    "outputId": "9008319b-7546-49b9-8b8a-c1e97e5c6454"
   },
   "outputs": [],
   "source": [
    "# Table 2: Performance on Task 1\n",
    "\n",
    "drop_user_columns = ['Reputation', 'CreationDate', 'LastAccessDate', 'num_posts']\n",
    "\n",
    "# model = LogisticRegression_\n",
    "model = DecisionTreeClassifier\n",
    "\n",
    "for K in list_of_K:\n",
    "    print('Task 1, K={}'.format(K))\n",
    "    train_features = [col for col in features_of_task1[K].columns \n",
    "                      if col not in drop_user_columns + ['is_churn']]\n",
    "\n",
    "    acc_list = learn_model(features_of_task1[K], train_features, model=model)\n",
    "    print('Accuracy: {}'.format(np.mean(acc_list)))\n",
    "    print('    for each folds: {}'.format(acc_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "ZgmKMwToWO_v",
    "outputId": "f35dca44-5477-4e5e-b1e2-1dced89d9e9d"
   },
   "outputs": [],
   "source": [
    "# Table 3: Performance on Task 2\n",
    "\n",
    "drop_user_columns = ['Reputation', 'CreationDate', 'LastAccessDate']\n",
    "\n",
    "# model = LogisticRegression_\n",
    "model = DecisionTreeClassifier\n",
    "\n",
    "for T in list_of_T:\n",
    "    print('Task 2, T={}'.format(T))\n",
    "    train_features = [col for col in features_of_task2[T].columns \n",
    "                      if col not in drop_user_columns + ['is_churn']]\n",
    "\n",
    "    acc_list = learn_model(features_of_task2[T], train_features, model=model)\n",
    "    print('Accuracy: {}'.format(np.mean(acc_list)))\n",
    "    print('    for each folds: {}'.format(acc_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFM2c6IXaGGu"
   },
   "outputs": [],
   "source": [
    "# Figure 5: Churn prediction accuracy when features from each category are used in isolation\n",
    "\n",
    "temporal_features = ['gap1', 'last_gap', 'time_since_last_post', 'mean_gap']\n",
    "frequency_features = ['num_answers', 'num_questions',\n",
    "                      'ans_que_ratio', 'num_posts']\n",
    "speed_features = ['answering_speed']\n",
    "quality_features = ['ans_score', 'que_score']\n",
    "consistency_features = ['ans_stddev', 'que_stddev']\n",
    "gratitude_features = ['ans_comments', 'que_comments']\n",
    "competitiveness_features = ['relative_rank_pos']\n",
    "content_features = ['ans_length', 'que_length']\n",
    "knowledge_features = ['accepted_answerer_rep', 'max_rep_answerer',\n",
    "                      'num_que_answered', 'time_for_first_ans',\n",
    "                      'rep_questioner', 'rep_answerers',\n",
    "                      'rep_co_answerers', 'num_answers_recvd']\n",
    "\n",
    "analysis_feature_names = {\n",
    "    'temporal': temporal_features,\n",
    "    'frequency': frequency_features,\n",
    "    'speed': speed_features,\n",
    "    'quality': quality_features,\n",
    "    'consistency': consistency_features,\n",
    "    'gratitude': gratitude_features,\n",
    "    'competitiveness': competitiveness_features,\n",
    "    'content': content_features,\n",
    "    'knowledge': knowledge_features,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ef5ac_2R1rPj",
    "outputId": "15d8001d-e584-4b73-84e3-b63b6788d1d8"
   },
   "outputs": [],
   "source": [
    "task1_accuracy_of_category = {}\n",
    "for name, feature_list in analysis_feature_names.items():\n",
    "    accuracy_of_category = []\n",
    "    for K in list_of_K:\n",
    "        if name == 'temoral':\n",
    "            feature_list = ['gap{}'.format(j) for j in range(1, K+1)]\n",
    "        elif name == 'frequency':\n",
    "            feature_list = [feat for feat in feature_list if feat != 'num_posts']\n",
    "        train_features = [feat for feat in feature_list if feat in features_of_task1[K].columns]\n",
    "        if len(train_features) == 0:\n",
    "            continue\n",
    "        print('\\n{}, Task 1, K={}'.format(name, K))\n",
    "        print('    columns: {}'.format(train_features))\n",
    "\n",
    "        acc_list = learn_model(features_of_task1[K], train_features)\n",
    "        mean_acc = np.mean(acc_list)\n",
    "        accuracy_of_category.append(mean_acc)\n",
    "        print('Accuracy: {}'.format(mean_acc))\n",
    "        print('    for each folds: {}'.format(acc_list))\n",
    "\n",
    "    task1_accuracy_of_category[name] = accuracy_of_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "colab_type": "code",
    "id": "ke9xkcjC9C3g",
    "outputId": "267db9ce-a3c2-4791-8e71-aad8b3904788"
   },
   "outputs": [],
   "source": [
    "# Bar Chart\n",
    "for title, predictions in task1_accuracy_of_category.items():\n",
    "    if len(predictions) == 0:\n",
    "        continue\n",
    "    n_groups = len(list_of_K)\n",
    "    index = np.arange(n_groups)\n",
    "\n",
    "    plt.bar(index, predictions, tick_label=list_of_K, align='center')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlim(-1, n_groups)\n",
    "    plt.ylim(40, 100)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 994
    },
    "colab_type": "code",
    "id": "TU8JkA8k1t28",
    "outputId": "8b5c84d2-38b2-43dc-8818-6f3de0f74405"
   },
   "outputs": [],
   "source": [
    "### Category Analysis - Task 2 ###\n",
    "task2_accuracy_of_category = {}\n",
    "for name, feature_list in analysis_feature_names.items():\n",
    "    accuracy_of_category = []\n",
    "    for T in list_of_T:\n",
    "        train_features = [feat for feat in feature_list if feat in features_of_task2[T].columns]\n",
    "        if len(train_features) == 0:\n",
    "            continue\n",
    "        print('\\n{}, Task 2, T={}'.format(name, T))\n",
    "        print('    columns: {}'.format(train_features))\n",
    "\n",
    "        acc_list = learn_model(features_of_task2[T], train_features)\n",
    "        mean_acc = np.mean(acc_list)\n",
    "        accuracy_of_category.append(mean_acc)\n",
    "        print('Accuracy: {}'.format(mean_acc))\n",
    "        print('    for each folds: {}'.format(acc_list))\n",
    "\n",
    "    task2_accuracy_of_category[name] = accuracy_of_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "colab_type": "code",
    "id": "r_4qFfOF1uHn",
    "outputId": "624b3155-57b0-41a0-eb43-0d5219ebbf5c"
   },
   "outputs": [],
   "source": [
    "# Bar Chart\n",
    "for title, predictions in task2_accuracy_of_category.items():\n",
    "    if len(predictions) == 0:\n",
    "        continue\n",
    "    n_groups = len(list_of_T)\n",
    "    index = np.arange(n_groups)\n",
    "\n",
    "    plt.bar(index, predictions, tick_label=list_of_T, align='center')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlim(-1, n_groups)\n",
    "    plt.ylim(50, 80)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0lkszL557Csg",
    "outputId": "b3de62d1-8f7d-4665-b603-299fa61e7539"
   },
   "outputs": [],
   "source": [
    "### Temporal Feature Analysis - Task 1 ###\n",
    "temporal_analysis_feature_func = {\n",
    "    'gapK': lambda K: ['gap{}'.format(j) for j in range(1, K+1)],\n",
    "    'last_gap': lambda K: ['gap{}'.format(K)]\n",
    "}\n",
    "\n",
    "\n",
    "task1_accuracy_with_time_gap = {}\n",
    "for K in list_of_K:\n",
    "    accuracy_with_time_gap = []\n",
    "    for name, feature_func in temporal_analysis_feature_func.items():\n",
    "        train_features = [feat for feat in feature_list if feat in features_of_task1[K].columns]\n",
    "        if len(train_features) == 0:\n",
    "            continue\n",
    "        print('\\n{}, Task 1, K={}'.format(name, K))\n",
    "        print('    columns: {}'.format(train_features))\n",
    "\n",
    "        acc_list = learn_model(features_of_task1[K], train_features)\n",
    "        mean_acc = np.mean(acc_list)\n",
    "        accuracy_with_time_gap.append(mean_acc)\n",
    "        print('Accuracy: {}'.format(mean_acc))\n",
    "        print('    for each folds: {}'.format(acc_list))\n",
    "\n",
    "    task1_accuracy_with_time_gap[K] = accuracy_with_time_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "colab_type": "code",
    "id": "yuFU5bd4_Efb",
    "outputId": "7cd75941-d6c5-4ffd-b9b0-4d0d9da9bbd6"
   },
   "outputs": [],
   "source": [
    "# Table 4: Temporal gap features analysis\n",
    "\n",
    "for K, acc in task1_accuracy_with_time_gap.items():\n",
    "    print(K, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8stSxGNbNPo9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Baseline (3).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
